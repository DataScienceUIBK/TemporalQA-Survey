<h1 align="center">
  <img src="images/hourglass.png" alt="Logo" width="55" style="vertical-align: middle; margin-right: 10px; position: relative; top: 8px;">
  It's High Time: A Survey of Temporal Question Answering
</h1>


<p align="center">
  <strong>Bhawna Piryani</strong> Â· Abdelrahman Abdallah Â· Jamshid Mozafari Â· Avishek Anand Â· Adam Jatowt  
  <br>
  <em>University of Innsbruck Â· TU Delft</em>
  <br><br>
  ğŸ“„ <a href="https://arxiv.org/abs/2505.20243v3">Read the Paper on arXiv</a> &nbsp;|&nbsp; ğŸ—“ï¸ <strong>2025</strong>
</p>

---

### ğŸ“˜ Overview

This repository accompanies our paper  on *Temporal Question Answering (TQA)* â€” exploring how AI models reason about time, adapt to evolving knowledge, and answer temporally constrained questions.

<p align="center">
  <img src="images/TemporalSurveyFigure.png" alt="Temporal QA Taxonomy" width="700">
</p>

---

## â¤ï¸ Recap

We present a comprehensive **survey of Temporal Question Answering (TQA)** â€” a field that studies how AI systems reason about *when* events happen, adapt to evolving knowledge, and answer **time-sensitive or time-dependent questions**.

We organize the literature along three major research pillars:

- **Temporal Representation and Understanding** â€” detecting and normalizing time expressions, estimating event and document focus time.  
- **Temporal Modeling and Reasoning** â€” temporal language models (TLMs) and retrieval-augmented generation (RAG) approaches for reasoning over time.  
- **Temporal Evaluation and Robustness** â€” datasets, benchmarks, and metrics assessing temporal consistency, recency awareness, and reasoning reliability.

<p align="center">
  <img src="images/TemporalSurveyFigure.png" alt="Temporal QA Taxonomy" width="700"><br>
  <em>Taxonomy of Temporal QA: datasets, benchmarks, and approaches</em>
</p>

---

## ğŸš€ Table of Contents

- [Overview](#overview)
- [1ï¸âƒ£ Temporal Foundations](#1ï¸âƒ£-temporal-foundations)
  - [1.1 Temporal Information Retrieval (TIR)](#11-temporal-information-retrieval-tir)
  - [1.2 Temporal Question Answering (TQA)](#12-temporal-question-answering-tqa)
- [2ï¸âƒ£ Datasets and Benchmarks](#2ï¸âƒ£-datasets-and-benchmarks)
  - [2.1 Diachronic & Synchronic Corpora](#21-diachronic--synchronic-corpora)
  - [2.2 Temporal QA Datasets](#22-temporal-qa-datasets)
- [3ï¸âƒ£ Methods and Models](#3ï¸âƒ£-methods-and-models)
  - [3.1 Temporal Language Models](#31-temporal-language-models)
  - [3.2 Temporal Retrieval-Augmented Generation (RAG)](#32-temporal-retrieval-augmented-generation-rag)
  - [3.3 Temporal Reasoning Capabilities](#33-temporal-reasoning-capabilities)
- [4ï¸âƒ£ Future Directions](#4ï¸âƒ£-future-directions)
- [ğŸ“š Citation](#-citation)
- [ğŸªª License](#-license)

---

## Overview

Temporal QA focuses on systems that can **understand, retrieve, and reason over time-dependent information**.  
This includes interpreting vague expressions like â€œrecentlyâ€ or â€œafter the war,â€ resolving temporal ambiguity, and aligning retrieved evidence with a questionâ€™s time frame.

---

## 1ï¸âƒ£ Temporal Foundations

### 1.1 Temporal Information Retrieval (TIR)
Time-aware retrieval aims to identify documents that are not only topically relevant but also **temporally aligned** with the queryâ€™s intent â€” e.g., â€œlatest Apple earningsâ€ or â€œclimate policy in 2015.â€

### 1.2 Temporal Question Answering (TQA)
Goes beyond retrieval by requiring reasoning over **temporal constraints**, such as ordering events or computing intervals (e.g., â€œAt what age did Obama win the Nobel Peace Prize?â€ â†’ 48 years).

---

## 2ï¸âƒ£ Datasets and Benchmarks

### 2.1 Diachronic & Synchronic Corpora
- **Diachronic**: Long-term archives (e.g., *NYT*, *Chronicling America*) capturing event evolution.  
- **Synchronic**: Snapshot datasets (e.g., *Wikipedia dumps*) reflecting world knowledge at a fixed time.

### 2.2 Temporal QA Datasets
Key datasets include **TimeQA**, **ArchivalQA**, **TempLAMA**, and **ComplexTempQA**, covering both explicit and implicit temporal reasoning.

---

## 3ï¸âƒ£ Methods and Models

### 3.1 Temporal Language Models
Models such as **TempoT5**, **TempoBERT**, and **BiTimeBERT** incorporate timestamps or temporal cues directly into their architecture for better time-aware representations.

### 3.2 Temporal Retrieval-Augmented Generation (RAG)
Approaches like **TempRetriever** and **TempRALM** integrate neural retrieval with generative reasoning to dynamically incorporate up-to-date evidence.

### 3.3 Temporal Reasoning Capabilities
Beyond modeling, recent works explore **event ordering**, **duration estimation**, and **temporal robustness** â€” testing whether LLMs can reason consistently over time.

---

## 4ï¸âƒ£ Future Directions

We highlight open challenges for building truly time-aware systems:
- Dynamic temporal knowledge management  
- Diachronicâ€“synchronic integration  
- Temporal uncertainty and confidence modeling  
- Multilingual and multimodal temporal reasoning  
- Implicit temporal intent detection  

---



## TableÂ ofÂ Contents
1. [Surveys & Tutorials](#surveys--tutorials)
2. [Temporal IRÂ â€“ Query & Ranking](#temporal-ir--query--ranking)
3. [Document Dating & Eventâ€‘Time Estimation](#document-dating--eventâ€‘time-estimation)
4. [Datasets & Benchmarks for Temporal QA](#datasets--benchmarks-for-temporal-qa)
5. [Temporal QAÂ â€“ Models & Methods](#temporal-qa--models--methods)
6. [Temporal Language Models & Representation Learning](#temporal-language-models--representation-learning)

---

## SurveysÂ &Â Tutorials
| Year | Title &Â Link | Citation key |
|------|--------------|--------------|
| 2025 | **From Matching to Generation: A Survey on Generative Information Retrieval** â€“ LiÂ *etÂ al.* [[ACM]](https://doi.org/10.1145/3722552) | `li2024matching` |
| 2023 | **Large Language Models for Information Retrieval:Â A Survey** â€“ ZhuÂ *etÂ al.* [[arXiv]](https://arxiv.org/abs/2308.07107) | `zhu2023large` |
| 2021 | **Retrieving and Reading:Â A Comprehensive Survey on Openâ€‘Domain Question Answering** â€“ ZhuÂ *etÂ al.* [[arXiv]](https://arxiv.org/abs/2101.00774) | `zhu2021retrieving` |
| 2016 | **Temporal Information Retrieval** (SIGIR tutorial) â€“ KanhabuaÂ &Â Anand [[ACM]](https://doi.org/10.1145/2911451.2914805) | `kanhabua2016temporal` |
| 2014 | **Survey of Temporal Information Retrieval and Related Applications** â€“ CamposÂ *etÂ al.* [[ACM]](https://doi.org/10.1145/2619088) | `campos2014survey` |

---

## Temporal IRÂ â€“ QueryÂ &Â Ranking
| Year | Title &Â Link | Citation key |
|------|--------------|--------------|
| 2009 | **Time Will Tell: Leveraging Temporal Expressions in IR** â€“ ArikanÂ *etÂ al.* |
| 2009 | **Improving Search Relevance for Implicitly Temporal Queries** â€“ MetzlerÂ *etÂ al.* |
| 2010 | **A Languageâ€‘Model Approach for Temporal Information Needs** â€“ BerberichÂ *etÂ al.* |
| 2010 | **Determining Time of Queries for Reâ€‘Ranking Search Results** â€“ KanhabuaÂ &Â NorvÃ¥g |
| 2007 | **Temporal Profiles of Queries** â€“ JonesÂ &Â Diaz |
| 2008 | **Answering General Timeâ€‘Sensitive Queries** â€“ DakkaÂ *etÂ al.* |
| 2014 | **Identifying Time Intervals of Interest to Queries** â€“ GuptaÂ &Â Berberich |
| 2003 | **Timeâ€‘Based Language Models** â€“ LiÂ &Â Croft |

---

## Document DatingÂ &Â Eventâ€‘Time Estimation
| Year | Title &Â Link | Citation key |
|------|--------------|--------------|
| 2021 | **Event Occurrence Date Estimation via Multivariate Timeâ€‘Series** â€“ WangÂ *etÂ al.* |
| 2018 | **Leveraging Linked Entities to Estimate Focus Time of Short Texts** â€“ MorbidoniÂ *etÂ al.* |
| 2017 | **Estimating Event Focus Time Using Neural Word Embeddings** â€“ DasÂ *etÂ al.* |
| 2017 | **Conceptâ€‘Driven Graphâ€‘Based Focusâ€‘Time Estimation** â€“ ShrivastavaÂ *etÂ al.* |
| 2018 | **Dating Documents with Graph Convolution Networks** â€“ VashishthÂ *etÂ al.* |
| 2013 | **Estimating Document Focus Time** â€“ JatowtÂ *etÂ al.* |
| 2012 | **Dating Texts without Explicit Temporal Cues** â€“ KumarÂ *etÂ al.* |
| 2008 | **Improving Temporal LMs for Dating Nonâ€‘Timestamped Docs** â€“ KanhabuaÂ &Â NorvÃ¥g |
| 2005 | **Temporal Language Models for Disclosure of Historical Text** â€“ JongÂ *etÂ al.* |

---

## DatasetsÂ &Â Benchmarks for TemporalÂ QA
| Year | Dataset | Paper / Link |
|------|---------|--------------|
| 2024 | **TimeBench** â€“ ChuÂ *etÂ al.* [[ACL]](https://aclanthology.org/2024.acl-long.66/) |
| 2024 | **TIQ** (Temporal QA with Implicit Constraints) â€“ JiaÂ *etÂ al.* [[ACM]](https://doi.org/10.1145/3589335.3651895) |
| 2024 | **ChroniclingAmericaQA** â€“ PiryaniÂ *etÂ al.* [[ACM]](https://doi.org/10.1145/3626772.3657891) |
| 2023 | **MenatQA** â€“ WeiÂ *etÂ al.* [[ACL]](https://aclanthology.org/2023.findings-emnlp.100/) |
| 2022 | **ArchivalQA** â€“ WangÂ *etÂ al.* [[ACM]](https://doi.org/10.1145/3477495.3531734) |
| 2021 | **A Dataset for Answering Timeâ€‘Sensitive Questions** â€“ ChenÂ *etÂ al.* (NeurIPSÂ Datasets) |
| 2020 | **TORQUE** â€“ NingÂ *etÂ al.* [[ACL]](https://aclanthology.org/2020.emnlp-main.88/) |
| 2018 | **TempQuestions** â€“ JiaÂ *etÂ al.* [[ACM]](https://doi.org/10.1145/3184558.3191536) |

---

## TemporalÂ QAÂ â€“ ModelsÂ &Â Methods
| Year | Title &Â Link | Citation key |
|------|--------------|--------------|
| 2024 | **Continual Learning for Temporalâ€‘Sensitive QA** â€“ YangÂ *etÂ al.* (IJCNN) |
| 2024 | **Enhancing Temporal Sensitivity &Â Reasoning for Timeâ€‘Sensitive QA** â€“ YangÂ *etÂ al.* [[ACL]](https://aclanthology.org/2024.findings-emnlp.848/) |
| 2023 | **Benchmarking &Â Improving Temporal Reasoning of LLMs** â€“ TanÂ *etÂ al.* [[ACL]](https://aclanthology.org/2023.acl-long.828/) |
| 2021 | **Improving QA for Eventâ€‘Focused Questions in News Collections** â€“ WangÂ *etÂ al.* (IRÂ Journal) |
| 2020 | **Machine Reading of Historical Events** â€“ HonovichÂ *etÂ al.* [[ACL]](https://aclanthology.org/2020.acl-main.668/) |
| 2009 | **Enhancing QA with Complex Temporal Question Processing** â€“ SaqueteÂ *etÂ al.* |
| 2005 | **QA Based on Temporal Inference** â€“ HarabagiuÂ &Â Bejan |
| 2004 | **Splitting Complex Temporal Questions for QA Systems** â€“ SaqueteÂ *etÂ al.* |

---

## Temporal Language ModelsÂ &Â RepresentationÂ Learning
| Year | Title &Â Link | Citation key |
|------|--------------|--------------|
| 2024 | **Timeâ€‘Sensitive Knowledge Editing via Efficient Finetuning** â€“ GeÂ *etÂ al.* [[ACL]](https://aclanthology.org/2024.acl-short.53/) |
| 2023 | **Efficient Continueâ€‘Training of Temporal LMs with Structural Info** â€“ SuÂ *etÂ al.* [[ACL]](https://aclanthology.org/2023.findings-emnlp.418/) |
| 2023 | **Salient Span Masking for Temporal Understanding** â€“ ColeÂ *etÂ al.* [[ACL]](https://aclanthology.org/2023.eacl-main.222/) |
| 2023 | **BiTimeBERT: Extending PLMs with Biâ€‘Temporal Information** â€“ WangÂ *etÂ al.* [[ACM]](https://doi.org/10.1145/3539618.3591686) |
| 2022 | **Timeâ€‘Aware LMs as Temporal KBs** â€“ DhingraÂ *etÂ al.* [[TACL]](https://aclanthology.org/2022.tacl-1.15/) |
| 2022 | **Time Masking for Temporal LMs** â€“ RosinÂ *etÂ al.* [[ACM]](https://doi.org/10.1145/3488560.3498529) |
| 2022 | **Temporal Attention for Language Models** â€“ RosinÂ &Â Radinsky [[ACL]](https://aclanthology.org/2022.findings-naacl.112/) |
| 2022 | **Temporal Effects on Preâ€‘trained Models** â€“ AgarwalÂ &Â Nenkova [[TACL]](https://aclanthology.org/2022.tacl-1.53/) |
| 2021 | **Dynamic Contextualised Word Embeddings** â€“ HofmannÂ *etÂ al.* [[ACL]](https://aclanthology.org/2021.acl-long.542/) |
| 2021 | **Mind the Gap: Assessing Temporal Generalisation in NLMs** â€“ LazaridouÂ *etÂ al.* (NeurIPS) |
| 2019 | **Neural Temporality Adaptation for Document Classification** â€“ HuangÂ &Â Paul [[ACL]](https://aclanthology.org/P19-1403/) |

---

## ğŸªªLicense
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## âœ¨Citation
If you find this work useful, please cite [ğŸ“œour paper](https://arxiv.org/pdf/2505.20243):
### Plain
Piryani, B., Abdullah, A., Mozafari, J., Anand, A., & Jatowt, A. (2025). It's High Time: A Survey of Temporal Question Answering. arXiv preprint arXiv:2505.20243.
### Bibtex
```bibtex
@article{piryani2025s,
  title={It's High Time: A Survey of Temporal Question Answering},
  author={Piryani, Bhawna and Abdullah, Abdelrahman and Mozafari, Jamshid and Anand, Avishek and Jatowt, Adam},
  journal={arXiv preprint arXiv:2505.20243},
  year={2025}
}

```
